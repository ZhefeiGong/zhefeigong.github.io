---
layout: post
title: "ğŸ›¸UFOGen: You Forward Once Large Scale Text-to-Image Generation via Diffusion GANs"
# description: >
#   ì´ ë…¼ë¬¸ì„ ì½ì–´ë³´ì•˜ìŠµë‹ˆë‹¹
sitemap: true
hide_last_modified: false
category: [paper, diffusion, todo]
---

<a href="https://arxiv.org/abs/2311.09257">arxiv</a>

# ìš”ì 
- **ODE trajectory learning** (noiseì™€ image pairë“¤ì„ ì¤€ë¹„í•˜ê³  supervisedë¡œ í•™ìŠµ) + **GAN discriminator** (ì´ìƒí•œ ê²°ê³¼ ë°©ì§€) ê°€ ê°€ëŠ¥í•¨ì„ ë³´ì¸ ë…¼ë¬¸
- **single inference**ë§Œìœ¼ë¡œ imageë¥¼ ìƒì„± ê°€ëŠ¥í•˜ë‹¤

# Abstract
- **Text-to-image** *diffusion modelì€* text promptë¥¼ coherent imageë¡œ ë³€í™˜í•˜ëŠ” ë†€ë¼ìš´ ëŠ¥ë ¥ì„ ì…ì¦í–ˆì§€ë§Œ, *multi-step* inferenceì˜ *computational cost*ëŠ” ì—¬ì „íˆ ë¬¸ì œì˜€ë‹¤
- í•´ê²°ì±…ìœ¼ë¡œì„œ ìš°ë¦¬ëŠ” **UFOGen**ì´ë¼ëŠ” ìƒˆë¡œìš´ generative modelì„ ì œì‹œí•œë‹¤. ì´ ëª¨ë¸ì€ ultra-fast **one-step** text-to-image generationì„ ìœ„í•´ designë˜ì—ˆë‹¤.
- (ê¸°ì¡´ì˜ conventional approachë“¤ì€ *sampler improving*ì´ë‚˜ diffusion modelì—ì˜ *distillation* ì‚¬ìš©ì— ì¤‘ì ì„ ë‘ì—ˆì§€ë§Œ,) UFOGenì€ **diffusion modelê³¼ GAN objectiveë¥¼ í†µí•©í•˜ëŠ” hybrid methology****ë¥¼ ì±„íƒí•œë‹¤.
- **diffusion-GAN objective**ì„ ìƒˆë¡­ê²Œ ë„ì…í•˜ê³  **pre-trained diffusion modelsë¥¼ í†µí•´ initialization**ì„ ì§„í–‰í•¨ìœ¼ë¡œì¨ UFOGenì€ textual descriptionì— ë”°ë¼ conditionëœ high-quality imageë¥¼ **single step**ë§Œì— íš¨ê³¼ì ìœ¼ë¡œ ìƒì„±í•œë‹¤.
- Traditional text-to-image generation ì™¸ì—ë„ UFOGenì€ applicationì—ì„œì˜ versatility(ë‹¤ì–‘ì„±)ì„ ë³´ì—¬ì¤€ë‹¤.
- íŠ¹íˆ UFOGenì€ **one-step text-to-image generation**ê³¼ ë‹¤ì–‘í•œ downstream taskë¥¼ ê°€ëŠ¥í•˜ê²Œ í•´ì£¼ëŠ” ì„ êµ¬ì ì¸ ëª¨ë¸ë“¤ ì¤‘ í•˜ë‚˜ë¡œì„œ, íš¨ìœ¨ì ì¸ ìƒì„±ëª¨ë¸ì˜ landscapeì—ì„œ ì¤‘ìš”í•œ ë°œì „ì„ ë³´ì—¬ì¤€ë‹¤.

# 1. Introduction
- diffusion modelì€ ìµœê·¼ generative modelì˜ ê°•ë ¥í•œ í•œ ì¢…ë¥˜ë¡œ ë¶€ìƒí–ˆìœ¼ë©°, ì—¬ëŸ¬ generative modeling taskì—ì„œ ì „ë¡€ì—†ëŠ” ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ê³  ìˆë‹¤.
  - íŠ¹íˆ, textë¡œ conditionëœ high-quality imageë¥¼ í•©ì„±í•˜ëŠ” ë° ëŠ¥í–ˆë‹¤.
  - ì´ task ì™¸ì—ë„, large-scaleì˜ text-to-image modelë“¤ì€ ì—¬ëŸ¬ downstream applicationì—ì„œ foundational(ê¸°ì´ˆì ) building blockìœ¼ë¡œ ê¸°ëŠ¥í•œë‹¤.
    - ì˜ˆ: personalized generation, controlled generation, image editing
- í•˜ì§€ë§Œ (ì¸ìƒì ì¸ generative qualityì™€ ê´‘ë²”ìœ„í•œ utility(ìœ ìš©ì„±)ì—ë„ ë¶ˆêµ¬í•˜ê³ ,) *diffusion model*ì€ ì¤‘ìš”í•œ í•œê³„ë¥¼ ê°€ì§€ê³  ìˆì—ˆëŠ”ë°, ë°”ë¡œ ì–˜ë„¤ëŠ” final sampleì„ generateí•˜ê¸° ìœ„í•´ *iterative denoising*ì— ì˜ì¡´í•œë‹¤ëŠ” ê²ƒì´ë‹¤. ì´ëŸ¬ë©´ generation speedëŠ” *slow*ì¼ ìˆ˜ë°–ì— ì—†ë‹¤.ğŸ¤¨
  - large-scale diffusion modelì˜... ëŠë¦° inferenceì™€ consequential computational demandëŠ” ì´ ëª¨ë¸ì„ ì¨ë¨¹ê¸° í˜ë“¤ê²Œ ë§Œë“œëŠ” ìš”ì¸ì´ ë˜ì—ˆë‹¤.
- Songì˜ seminal workì—ì„œ, diffusion modelì—ì„œì˜ samplingì€, ì‚¬ì‹¤ diffusion processì™€ ê´€ë ¨ëœ PF-ODEë¥¼ í’€ì–´ë‚´ëŠ” ê²ƒê³¼ equilvalentí•˜ë‹¤ëŠ” ê²ƒì´ ë°í˜€ì¡Œë‹¤.
  - PF-ODE = probability flow ordinary differential equation (í™•ë¥  íë¦„ ì¼ë°˜ ë¯¸ë¶„ë°©ì •ì‹)
- í˜„ì¬, diffusion modelì˜ sampling efficiencyë¥¼ ê°œì„ í•˜ê³ ì í•˜ëŠ” ì—°êµ¬ë“¤ì€ ëŒ€ë¶€ë¶„ ODE formulation (ê³µì‹í™”) ì— ì¤‘ì ì„ ë‘”ë‹¤.
- One line of work (í•œ ë¶„ì•¼ì˜ ì‘ì—…) ì€ PF-ODEì— ëŒ€í•œ numerical solverë¥¼ ë°œì „ì‹œí‚¤ë ¤ê³  í•œë‹¤. ì´ë¥¼ í†µí•´ discretization sizeê°€ ë”ìš± í° ODEë„ í•´ê²°ê°€ëŠ¥í•˜ê²Œ í•¨ìœ¼ë¡œì¨, ê¶ê·¹ì ìœ¼ë¡œëŠ” requisite (í•„ìš”í•œ) sampling step ìˆ˜ë¥¼ ì¤„ì´ë ¤ëŠ” ê²ƒì´ ëª©ì ì´ë‹¤.
  - ê·¸ëŸ¬ë‚˜ step sizeì™€ accuracy ê°„ì˜ inherent trade-offëŠ” ì—¬ì „íˆ ì¡´ì¬í•œë‹¤ğŸ˜µ
  - PF-ODEì˜ highly non-linear and complicated trajectoryë¥¼ ê³ ë ¤í•˜ë©´, required sampling step ìˆ˜ë¥¼ minimal level(ìµœì†Œ ìˆ˜ì¤€)ìœ¼ë¡œ ì¤„ì´ëŠ” ê²ƒì€ ê²ë‚˜ ì–´ë ¤ìš¸ ê²ƒì´ë‹¤.
  - ì‹¬ì§€ì–´ ê°€ì¥ ë°œì „ëœ solverì¡°ì°¨ë„ image generateì— 10~20 sampling stepì´ í•„ìš”í•˜ë©°, ì´ë¥¼ ë” ì¤„ì—¬ë²„ë¦¬ë©´ image qualityê°€ í™•ì—°íˆ ë–¨ì–´ì ¸ë²„ë¦°ë‹¤.
- ëŒ€ì•ˆì ì¸ approachëŠ” pre-trained diffusion modelë¡œë¶€í„° PF-ODE trajectoryë¥¼ distillí•˜ê³ ì í•œë‹¤.
  - trajectoryë¥¼ distillí•œë‹¤ëŠ”ê²Œ ë¬´ìŠ¨ëœ»ì¸ì§€ ëª¨ë¥´ê² ìŒ. TODO
  - distillationì˜ ê·¸ distillì¸ ë“¯!
  - ì˜ˆë¥¼ ë“¤ì–´, progressive distillation ê¸°ë²•ì€ / PF-ODE solverì˜ multiple discretizatio stepë“¤ì„ / single stepìœ¼ë¡œ ì••ì¶•í•˜ë ¤ê³  ì‹œë„í•œë‹¤ / by explicitly aligning (ì¼ì¹˜ì‹œí‚¤ê¸°) with the solver's output!
  - ë§ˆì°¬ê°€ì§€ë¡œ, consistency distillation ê¸°ë²•ì€ ODE trajectoryë¥¼ ë”°ë¼ point consistencyë¥¼ ìœ ì§€í•˜ëŠ”, consistency mappingì„ learní•˜ëŠ” ë°©ì‹ì´ë‹¤.
  - ì´ì™€ ê°™ì€ ê¸°ë²•ë“¤ì€ sampling step ìˆ˜ë¥¼ ìƒë‹¹íˆ ì¤„ì¼ ìˆ˜ ìˆëŠ” potentialì„ ë³´ì—¬ì£¼ì—ˆë‹¤.
  - í•˜ì§€ë§Œ, ODE trajectoryì˜ intrinsic(ë³¸ì§ˆì ì¸) complexityë¡œ ì¸í•´, extremely small step regimeì—ì„œëŠ” ë‹¤ë“¤ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆë‹¤. íŠ¹íˆ large-scale text-to-image diffusion modelì—ì„œëŠ”.
  - 

# 2. Related Works

## (2.1) Text-to-image Diffusion Models

## (2.2) Accelerating Diffusion Models

## (2.3) Text-to-image GANs

## (2.4) Recent Progress on Few-step Text-to-image Generation

# 3. Background

## (3.1) Diffusion Models

## (3.2) Diffusion-GAN Hybrids

# 4. Methods
- ì´ ì„¹ì…˜ì€ ìš°ë¦¬ê°€ diffusion-GAN hybrid modelì—ì„œ ê°œì„ í•˜ì—¬ UFOGen modelì„ íƒ„ìƒì‹œí‚¨ ë¶€ë¶„ë“¤ì— ëŒ€í•´ ë‹¤ë£¬ë‹¤.
- ì´ëŸ¬í•œ ê°œì„ ì‚¬í•­ë“¤ì€ ë‘ ê°€ì§€ ë¶€ë¶„ì— ì´ˆì ì´ ë§ì¶°ì ¸ ìˆë‹¤.
1. enabling **one step sampling** (section 4.1ì—ì„œ í›„ìˆ )
2. **scaling-up** for text-to-image generation (section 4.2ì—ì„œ í›„ìˆ )
  - **pre-trained diffusion model**ì„ í™œìš©í•œ initialization!

## 4.1 Enabling One-step Sampling for UFOGen
- **diffusion-GAN hybrid model**ì€ **trainingì„ large denoising step sizeë¡œ** í•˜ë„ë¡ ë§ì¶¤ì œì‘ë˜ì—ˆë‹¤ (tailored)
- ê·¸ëŸ¬ë‚˜ ì´ ëª¨ë¸ì„ *single denoising stepë§Œìœ¼ë¡œ train*í•˜ë ¤ëŠ” ì‹œë„ëŠ”, ì‚¬ì‹¤ìƒ model trainingì„ conventional GANì˜ trainingìœ¼ë¡œ reduceí•´ë²„ë¦¬ê² ë‹¤ëŠ” ê²ƒì´ë‹¤ğŸ˜Ÿ
  - single denoising stepìœ¼ë¡œ modelì„ trainí•˜ìëŠ” ê±´ $$x_{T-1} = x_0$$ì„ ì˜ë¯¸í•œë‹¤.
  - ê²°ê³¼ì ìœ¼ë¡œ ê·¸ë™ì•ˆì˜ (prior) diffusion-GAN modelë“¤ì€ one-step samplingì„ ë‹¬ì„±í•  ìˆ˜ ì—†ì—ˆë‹¤ğŸ˜Ÿ
    - ì™œ??? TODO ğŸ‘»
- ì´ëŸ¬í•œ challengeë¥¼ ê³ ë ¤í•˜ì—¬, ìš°ë¦¬ëŠ” **SIDDM formulation**ì„ ì‹¬ì¸µê²€í† í•˜ê³ , **generatorì˜ parameterization**ê³¼ **objective ì†ì˜ reconstruction term**ì„ ìˆ˜ì •í•˜ì˜€ë‹¤.
- ì´ëŸ¬í•œ ì¡°ì •ì€ UFOGenì´, ì—¬ì „íˆ **trainì€ several denoising step**ì„ í†µí•´ ì§„í–‰í•˜ë©´ì„œë„, **samlingì€ one-stepìœ¼ë¡œ** í•  ìˆ˜ ìˆê²Œ í•´ì£¼ì—ˆë‹¤.

### (4.1.1) Parameterization of the Generator
- diffusion-GAN modelì—ì„œ, generatorëŠ” $$x_{t-1}$$ì˜ sampleì„ ìƒì„±í•´ì•¼ í•œë‹¤.
- ê·¸ëŸ¬ë‚˜, *($$x_{t-1}$$ì„ directly outputtingí•˜ëŠ” ëŒ€ì‹ )*, DDGANê³¼ SIDDNì˜ generatorëŠ” 
  $$ p_\theta(x_{t-1} | x_t) = q(x_{t-1}|x_t, x_0 = G_\theta(x_t, t)) $$ ë¡œ parameterizedëœë‹¤.
  - ì¦‰, ë¨¼ì € $$ x_0 $$ ê°€ denoising generator $$G_\theta(x_t, t)$$ë¥¼ í†µí•´ predictë˜ê³ , 
    ê·¸ ë‹¤ìŒì— $$x_{t-1}$$ ì€ $$q(x_{t-1}|x_t, x_0$$ë¼ëŠ” Gaussian posterior distributionì„ í†µí•´ samplingëœë‹¤.
  - ì°¸ê³ ë¡œ, ì´ parameterizationì€ ì‹¤ìš©ì ì¸ ëª©ì ì„ ìœ„í•œ ê²ƒì´ë©°, alternative parameterizationì€ model formulationì„ breakí•˜ì§€ (ê¹¨ëœ¨ë¦¬ì§€) ì•ŠëŠ”ë‹¤.
- ìš°ë¦¬ëŠ” generatorì— ëŒ€í•œ ë˜ë‹¤ë¥¸ íƒ€ë‹¹í•œ parameterizationì„ ì œì•ˆí•œë‹¤ - 
  $$p_\theta(x_{t-1}) = q(x_{t-1} | x_0 = G_\theta(x_t, t))$$
  - generatorëŠ” ì—¬ì „íˆ $$x_0$$ë¥¼ predictí•˜ì§€ë§Œ, ìš°ë¦¬ëŠ” $$x_{t-1}$$ì„ (posteriorê°€ ì•„ë‹ˆë¼) 
    forward diffusion process, ì¦‰ $$q(x_{t-1}|x_0)$$ë¥¼ í†µí•´ samplingí•œë‹¤.
  - í›„ìˆ í•˜ê² ì§€ë§Œ, ì´ëŸ¬í•œ ì„¤ê³„ëŠ” $$x_0$$ì—ì„œ distribution matchingì„ í—ˆìš©í•¨ìœ¼ë¡œì¨ one-step samplingì— ì´ë°”ì§€í•œë‹¤.
    - distribution matching ë­ì§€? TODO

### (4.1.2) Improved Reconstruction Loss at $$x_0$$
- (4.1.1ì˜) ìƒˆë¡œìš´ generator parameterizationì„ ì“°ê²Œ ë˜ë©´, Equation 4ì— ë“±ì¥í•˜ëŠ” SIDDMì˜ objectiveëŠ” $$x_0$$ì—ì„œì˜ distributionê³¼ indirecty matchëœë‹¤.
- ì´ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ ìš°ë¦¬ëŠ”, adversarial objectiveì™€ KL objectiveë¥¼ ë³„ë„ë¡œ ë¶„ì„í•œë‹¤. (ë‘˜ ë‹¤ Equation 4ì— ë“±ì¥)
- (Equation 4ì˜) first termì€ adversarial divergence 
  $$D_{adv}(q(x_{t-1}||p_\theta(x'_{t-1})))$$
  ì„ minimizeí•œë‹¤.
  - ì—¬ê¸° ë‚˜ì˜¤ëŠ” ë‘ ë¶„í¬ $$q_(x_{t-1})$$ê³¼ $$p_\theta(x'_{t-1})$$ì€, ê°ê° $$x_0$$ì˜ distributionì´ (ì„œë¡œ ë™ì¼í•œ) Gaussian kernelì— ì˜í•´ corrputëœ ê²ƒì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤\dots
  - 

### (4.1.3) Training and Sampling of UFOGen

## 4.2 Leverage Pre-trained Diffusion Models (-> scaling-up for text-to-image generation)
### ë¬¸ì œ
- ìš°ë¦¬ì˜ ëª©í‘œëŠ” ultra-fast text-to-img ëª¨ë¸ì„ ë§Œë“œëŠ” ê²ƒì´ë‹¤.
- ê·¼ë° effective UFOGen recipeì—ì„œ **web-scale data**ë¡œì˜ transitionì€ challengingí•˜ë‹¤.
- (text-to-img ìƒì„±ì„ ìœ„í•œ diffusion-GAN hybrid modelì—ì„œ) **training**ì´ ì—¬ëŸ¬ëª¨ë¡œ ë³µì¡í•˜ê¸° ë•Œë¬¸ ã… ã… 
  - íŠ¹íˆ **discriminator**(íŒë³„ì)ëŠ”, text-image alignmentì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ texture(ì§ˆê°)ê³¼ semantics(ì˜ë¯¸) ë‘˜ë‹¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŒë‹¨ì„ ë‚´ë ¤ì•¼ í•œë‹¤.
  - ì´ challengeëŠ” trainingì˜ **initial stage**(ì´ˆê¸°ë‹¨ê³„)ì—ì„œ íŠ¹íˆ ë‘ë“œëŸ¬ì§„ë‹¤.
  - ê²Œë‹¤ê°€ text-to-imgae modelì˜ trainingì€ costê°€ ì—„ì²­ ë†’ì„ ìˆ˜ ìˆë‹¤ - íŠ¹íˆ GAN ê¸°ë°˜ ëª¨ë¸ì˜ ê²½ìš° discriminatorê°€ ì¶”ê°€ì ìœ¼ë¡œ parameterë¥¼ ê°–ê³ ìˆë‹¤ã… ã… 
  - ìˆœìˆ˜ GAN ê¸°ë°˜ì˜ text-to-img ëª¨ë¸ì€ ì´ëŸ° ë³µì¡ì„± ë•Œë¬¸ì— ë§¤ìš° ë³µì¡í•˜ê³  ë¹„ì‹¼ trainingì„ ì´ˆë˜í•œë‹¤
### í•´ê²°
- diffusion-GAN hybrid modelì„ scaling-upí•˜ëŠ” challengeë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” **pre-trained text-to-image diffusion model**, íŠ¹íˆ **stable diffusion model**ì„ í™œìš©í•  ê²ƒì„ ì œì•ˆí•œë‹¤.
  - êµ¬ì²´ì ìœ¼ë¡œ, UFOGen ëª¨ë¸ì€ generatorì™€ discriminator ëª¨ë‘ì— ì¼ê´€ëœ UNet structureë¥¼ ì‚¬ìš©í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆë‹¤.
  - ì´ designì€ pre-trained stable diffusion modelì„ ì´ìš©í•œ initializationì´ ì›í™œí•˜ë„ë¡ í•´ì¤€ë‹¤.
  - ìš°ë¦¬ëŠ” stable diffusion modelì˜ internal feature (ë‚´ë¶€ì˜ íŠ¹ì§•) ë“¤ì´ textual & visual data ì‚¬ì´ì˜ ë³µì¡í•œ interplay (ìƒí˜¸ì‘ìš©) ì— ëŒ€í•´ rich informationì„ í¬í•¨í•˜ê³  ìˆë‹¤ê³  ê°€ì •í•œë‹¤.
### ì„±ê³¼
- ì´ initialization ì „ëµì€ UFOGenì˜ trainingì„ ìƒë‹¹íˆ ê°„ì†Œí™”í•´ì¤€ë‹¤.
  - stable diffusion modelë¡œ UFOGenì˜ generatorì™€ discriminatorë¥¼ initializeí•œ í›„, ìš°ë¦¬ëŠ” stable training dynamics (ì•ˆì •ì ì¸ training ë™ì—­í•™) ê³¼ ë†€ëë„ë¡ ë¹ ë¥¸ convergence (ìˆ˜ë ´) ì„ ê´€ì°°í•  ìˆ˜ ìˆì—ˆë‹¤.
- UFOGenì˜ ì™„ì „í•œ í›ˆë ¨ ì „ëµì€ ë‹¤ìŒì˜ Fig 3ì— ë‚˜íƒ€ë‚˜ ìˆë‹¤.
![Full-width image](/assets/img/blog/2024-02-25-UFOGen-Fig3.png)

# 5. Experiments

# 6. Conclusions
- UFOGen
  - text-to-image synthesis(í•©ì„±)ì—ì„œì˜ ì—„ì²­ë‚œ ë°œì „
  - inference efficiencyë¼ëŠ” challengeë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í•´ê²°
- ì°½ì˜ì ì¸ hybrid approach: diffusion modelê³¼ GAN objectiveë¥¼ í•©ì¹¨
  - UFOGenì´ text descriptionìœ¼ë¡œë¶€í„° high-quality image ìƒì„±í•˜ëŠ”ê±¸ ultra-fast & one-step ë¡œ í•  ìˆ˜ ìˆê²Œ í•´ì¤€ë‹¤
- UFOGenì´ ê¸°ì¡´ì˜ accelerated diffusion-based methodë“¤ë³´ë‹¤ ìš°ì›”í•˜ë‹¤
  - ì¢…í•©ì ì¸ í‰ê°€ë“¤ë¡œë¶€í„° ì¼ê´€ë˜ê²Œ í™•ì¸ë¨
- UFOGenì€ one-step text-to-image synthesisë¥¼ ë…íŠ¹í•˜ê²Œ ì˜í•˜ê³ , downstream taskë“¤ì— ìˆì–´ì„œë„ ìˆ™ë ¨ë„ê°€ ë†’ë‹¤
- ultra-fast ì†ë„ì˜ text-to-image synthesisê°€ ê°€ëŠ¥í•˜ê²Œ í•´ì£¼ëŠ” ì„ êµ¬ì
  - gen. models landscapeì—ì„œ transformative shiftì˜ ê¸¸ì„ ì—´ì–´ì¤€ë‹¤
  - UFOGenì˜ impactëŠ” academic discourse(ë…¼ì˜)ë¥¼ ë„˜ì–´, ë¹ ë¥´ê³  ê³ í€„ì¸ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ë° ìˆì–´ í˜ëª…ì ì¸ ì‹¤ìš©ì„±ì„ ë³´ì—¬ì¤„ ê²ƒì´ë‹¤